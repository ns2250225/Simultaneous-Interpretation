import os
import asyncio
import base64
import json
import websockets
import pyaudio
import ssl
import time
from array import array
from urllib.parse import urlparse
try:
    import certifi
    HAVE_CERTIFI = True
except Exception:
    HAVE_CERTIFI = False

# --- é…ç½®éƒ¨åˆ† ---
API_KEY = os.environ.get("OPENAI_API_KEY", "sk-7zp54GI1xp4alaQuydzcxMLhZW47jJAcIJSJksEo7Vfp18Rd")

MODEL_NAME = os.environ.get("OPENAI_TRANSLATION_MODEL", "gpt-4o-realtime-preview")

BASE_URL = os.environ.get("OPENAI_BASE_URL", "ws://jeniya.top")
URL = f"{BASE_URL}/v1/realtime?model={MODEL_NAME}"

# éŸ³é¢‘è®¾ç½®
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 24000  # Realtime API é»˜è®¤é€šå¸¸æ¨è 24kHz
CHUNK = 1024  # æ¯æ¬¡è¯»å–çš„éŸ³é¢‘å¸§å¤§å°

class RealtimeTranslator:
    def __init__(self, target_language="English"):
        self.target_language = target_language
        self.p = pyaudio.PyAudio()
        self.audio_in_stream = None
        self.audio_out_stream = None
        self._transcript_buffer = ""
        self._translation_buffer = ""
        self._last_transcript_line = ""
        self._last_translation_line = ""
        self._last_transcript_chunk = ""
        self._last_translation_chunk = ""
        self._transcript_printed = False
        self._translation_printed = False
        self._transcript_done = False
        self._translation_done = False

    def setup_audio(self):
        """åˆå§‹åŒ–éº¦å…‹é£è¾“å…¥å’Œæ‰¬å£°å™¨è¾“å‡ºæµ"""
        # è¾“å…¥æµ (éº¦å…‹é£)
        self.audio_in_stream = self.p.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK
        )
        # è¾“å‡ºæµ (æ‰¬å£°å™¨)
        self.audio_out_stream = self.p.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            output=True,
            frames_per_buffer=CHUNK
        )

    async def send_audio(self, websocket):
        """æŒç»­è¯»å–éº¦å…‹é£æ•°æ®å¹¶å‘é€ç»™ API"""
        print("ğŸ¤ å¼€å§‹é€šè¿‡éº¦å…‹é£å½•éŸ³...")
        try:
            vad_enabled = (os.environ.get("OPENAI_VAD_ENABLED", "1").strip().lower() in ("1", "true", "yes"))
            silence_ms = int(os.environ.get("OPENAI_VAD_SILENCE_MS", "500") or "500")
            min_speech_ms = int(os.environ.get("OPENAI_VAD_MIN_SPEECH_MS", "300") or "300")
            threshold = int(os.environ.get("OPENAI_VAD_THRESHOLD", "500") or "500")
            commit_interval_ms = int(os.environ.get("OPENAI_COMMIT_INTERVAL_MS", "1200") or "1200")
            last_commit = time.monotonic()
            speaking = False
            seg_start = 0.0
            last_voice = time.monotonic()
            while True:
                # 1. ä»éº¦å…‹é£è¯»å–åŸå§‹ PCM æ•°æ® (éé˜»å¡æ–¹å¼è¯»å–ç¨å¾®å¤æ‚ï¼Œè¿™é‡Œç”¨ç®€å•çš„é˜»å¡è¯»å–é…åˆ asyncio.to_thread æ›´å¥½ï¼Œä½†åœ¨å¾ªç¯ä¸­ç›´æ¥è¯»ä¹Ÿå¯ä»¥)
                # ä¸ºäº†é¿å…é˜»å¡ asyncio äº‹ä»¶å¾ªç¯ï¼Œè¿™é‡Œä½¿ç”¨ await asyncio.sleep(0) è®©å‡ºæ§åˆ¶æƒï¼Œæˆ–è€…ä½¿ç”¨ run_in_executor
                data = await asyncio.to_thread(self.audio_in_stream.read, CHUNK, exception_on_overflow=False)
                
                # 2. Base64 ç¼–ç 
                base64_audio = base64.b64encode(data).decode("utf-8")
                
                # 3. å‘é€ç»™ OpenAI
                event = {
                    "type": "input_audio_buffer.append",
                    "audio": base64_audio
                }
                await websocket.send(json.dumps(event))
                
                now = time.monotonic()
                if vad_enabled:
                    samples = array('h')
                    samples.frombytes(data)
                    peak = max((abs(x) for x in samples), default=0)
                    if peak >= threshold:
                        last_voice = now
                        if not speaking:
                            speaking = True
                            seg_start = now
                    elif speaking and (now - last_voice) * 1000 >= silence_ms and (now - seg_start) * 1000 >= min_speech_ms:
                        try:
                            await websocket.send(json.dumps({"type": "input_audio_buffer.commit"}))
                            await websocket.send(json.dumps({"type": "response.create"}))
                        except Exception:
                            pass
                        speaking = False
                        seg_start = 0.0
                else:
                    if (now - last_commit) * 1000 >= commit_interval_ms:
                        try:
                            await websocket.send(json.dumps({"type": "input_audio_buffer.commit"}))
                            await websocket.send(json.dumps({"type": "response.create"}))
                        except Exception:
                            pass
                        last_commit = now
                await asyncio.sleep(0)
        except Exception as e:
            print(f"å‘é€éŸ³é¢‘å‡ºé”™: {e}")

    async def receive_audio(self, websocket):
        """æ¥æ”¶ API è¿”å›çš„æ•°æ®å¹¶æ’­æ”¾"""
        print("ğŸ”Š å‡†å¤‡æ¥æ”¶ç¿»è¯‘éŸ³é¢‘...")
        try:
            async for message in websocket:
                event = json.loads(message)
                event_type = event.get("type")

                # å¤„ç†è¿”å›çš„éŸ³é¢‘å¢é‡æ•°æ®
                if event_type == "response.audio.delta":
                    audio_content = event.get("delta")
                    if audio_content:
                        # è§£ç  base64 å¹¶å†™å…¥æ‰¬å£°å™¨æµ
                        audio_data = base64.b64decode(audio_content)
                        self.audio_out_stream.write(audio_data)
                
                elif event_type == "response.audio_transcript.delta":
                    self._emit_transcription(event.get("delta", ""))
                elif event_type == "response.audio_transcript.done":
                    self._transcript_done = True
                    self._flush_transcription()
                
                elif event_type == "response.output_text.delta":
                    self._emit_translation(event.get("delta", ""))
                elif event_type == "response.output_text.done":
                    self._translation_done = True
                    self._flush_translation()
                
                elif event_type == "response.text.delta":
                    self._emit_translation(event.get("delta", ""))
                elif event_type == "response.text.done":
                    self._translation_done = True
                    self._flush_translation()
                
                elif event_type == "error":
                    print(f"\nâŒ API é”™è¯¯: {event.get('error')}")

        except Exception as e:
            print(f"æ¥æ”¶éŸ³é¢‘å‡ºé”™: {e}")

    async def run(self):
        self.setup_audio()
        
        if not API_KEY:
            raise RuntimeError("ç¼ºå°‘ OPENAI_API_KEY ç¯å¢ƒå˜é‡")

        headers = {
            "Authorization": f"Bearer {API_KEY}",
            "OpenAI-Beta": "realtime=v1",
        }

        print(f"ğŸ”— æ­£åœ¨è¿æ¥åˆ° {MODEL_NAME} ...")
        ssl_ctx = ssl.create_default_context()
        custom_cafile = os.environ.get("OPENAI_CA_CERT") or os.environ.get("SSL_CERT_FILE")
        if isinstance(custom_cafile, str) and os.path.isfile(custom_cafile):
            try:
                ssl_ctx.load_verify_locations(cafile=custom_cafile)
            except Exception:
                pass
        elif HAVE_CERTIFI:
            try:
                ssl_ctx.load_verify_locations(cafile=certifi.where())
            except Exception:
                pass
        allow_insecure = (os.environ.get("ALLOW_INSECURE_SSL", "").strip().lower() in ("1", "true", "yes"))
        if allow_insecure:
            try:
                ssl_ctx.check_hostname = False
                ssl_ctx.verify_mode = ssl.CERT_NONE
            except Exception:
                pass

        parsed = urlparse(URL)
        ws_kwargs = {
            "additional_headers": headers,
            "ping_interval": None,
            "ping_timeout": None,
            "max_size": 1000000000,
        }
        if parsed.scheme == "wss":
            ws_kwargs["ssl"] = ssl_ctx
        async with websockets.connect(URL, **ws_kwargs) as websocket:
            print("âœ… è¿æ¥æˆåŠŸï¼è¯·å¼€å§‹è¯´è¯ (æŒ‰ Ctrl+C åœæ­¢)")

            # 1. å‘é€ Session é…ç½®ï¼šè®¾ç½® VAD (è‡ªåŠ¨è¯´è¯æ£€æµ‹) å’Œ ç³»ç»ŸæŒ‡ä»¤
            session_update = {
                "type": "session.update",
                "session": {
                    "modalities": ["text", "audio"],
                    "instructions": (
                        "You are a professional simultaneous interpreter. "
                        f"Your task is to translate whatever the user says into {self.target_language} immediately. "
                        "Do not answer the user's question, just translate the content. "
                        f"If the user speaks {self.target_language}, repeat it clearly or improve the phrasing slightly."
                    ),
                    "voice": "alloy",  # å¯é€‰: alloy, echo, shimmer
                    "input_audio_format": "pcm16",
                    "output_audio_format": "pcm16",
                    "turn_detection": {
                        "type": "server_vad", # å¯ç”¨æœåŠ¡ç«¯è¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼Œè¯´å®Œè¯è‡ªåŠ¨å›å¤
                    }
                }
            }
            await websocket.send(json.dumps(session_update))

            # 2. å¹¶è¡Œè¿è¡Œ å‘é€ å’Œ æ¥æ”¶ ä»»åŠ¡
            await asyncio.gather(
                self.send_audio(websocket),
                self.receive_audio(websocket)
            )

    def close(self):
        if self.audio_in_stream:
            self.audio_in_stream.stop_stream()
            self.audio_in_stream.close()
        if self.audio_out_stream:
            self.audio_out_stream.stop_stream()
            self.audio_out_stream.close()
        self.p.terminate()

    def _append_incremental(self, buf: str, chunk: str) -> str:
        s = (chunk or "").strip()
        if not s:
            return buf
        if s in buf:
            return buf
        max_overlap = min(len(buf), len(s))
        for k in range(max_overlap, 0, -1):
            if buf[-k:] == s[:k]:
                return buf + s[k:]
        return buf + s

    def _emit_transcription(self, chunk: str) -> None:
        if not chunk:
            return
        if chunk == self._last_transcript_chunk:
            return
        self._last_transcript_chunk = chunk
        new_buf = self._append_incremental(self._transcript_buffer, chunk)
        if new_buf != self._transcript_buffer:
            self._transcript_printed = False
            self._transcript_buffer = new_buf
        if self._transcript_done and not self._transcript_printed:
            line = self._transcript_buffer.strip()
            if line and line != self._last_transcript_line:
                print(f"ğŸŸ¨ è½¬å½•: {line}")
                self._last_transcript_line = line
            self._transcript_buffer = ""
            self._transcript_printed = True
            self._transcript_done = False

    def _emit_translation(self, chunk: str) -> None:
        if not chunk:
            return
        if chunk == self._last_translation_chunk:
            return
        self._last_translation_chunk = chunk
        new_buf = self._append_incremental(self._translation_buffer, chunk)
        if new_buf != self._translation_buffer:
            self._translation_printed = False
            self._translation_buffer = new_buf
        if self._translation_done and not self._translation_printed:
            line = self._translation_buffer.strip()
            if line:
                last = self._last_translation_line
                if not last or (line != last and not line.startswith(last) and not last.startswith(line)):
                    print(f"ğŸŸ¦ ç¿»è¯‘: {line}")
                    self._last_translation_line = line
            self._translation_buffer = ""
            self._translation_printed = True
            self._translation_done = False

    def _flush_transcription(self) -> None:
        if not self._transcript_printed and self._transcript_buffer.strip() and self._transcript_buffer.strip() != self._last_transcript_line:
            print(f"ğŸŸ¨ è½¬å½•: {self._transcript_buffer.strip()}")
            self._last_transcript_line = self._transcript_buffer.strip()
        self._transcript_buffer = ""
        self._transcript_printed = True
        self._transcript_done = False

    def _flush_translation(self) -> None:
        line = self._translation_buffer.strip()
        if line and not self._translation_printed:
            last = self._last_translation_line
            if not last or (line != last and not line.startswith(last) and not last.startswith(line)):
                print(f"ğŸŸ¦ ç¿»è¯‘: {line}")
                self._last_translation_line = line
        self._translation_buffer = ""
        self._translation_printed = True
        self._translation_done = False

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="OpenAI Realtime Translator")
    parser.add_argument("--target-language", default="English", help="Target language for translation (default: English)")
    args = parser.parse_args()

    translator = RealtimeTranslator(target_language=args.target_language)
    try:
        asyncio.run(translator.run())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²åœæ­¢")
    finally:
        translator.close()
