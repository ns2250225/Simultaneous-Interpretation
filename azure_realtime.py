import azure.cognitiveservices.speech as speechsdk
import time
import re
import os
from xml.sax.saxutils import escape

def start_voice_interpreter():
    speech_key = os.getenv("AZURE_SPEECH_KEY")
    service_region = os.getenv("AZURE_SERVICE_REGION")
    if not speech_key or not service_region:
        print("ç¼ºå°‘ AZURE_SPEECH_KEY æˆ– AZURE_SERVICE_REGION ç¯å¢ƒå˜é‡")
        return

    # 1. ç¿»è¯‘é…ç½®
    translation_config = speechsdk.translation.SpeechTranslationConfig(
        subscription=speech_key, region=service_region)
    translation_config.add_target_language("zh-Hans")
    translation_config.add_target_language("en")

    # 2. è‡ªåŠ¨è¯­è¨€æ£€æµ‹é…ç½®
    # === å…³é”®ä¿®æ”¹ï¼šæŠŠ en-US æ”¾åœ¨ç¬¬ä¸€ä½ï¼Œå¢åŠ è‹±æ–‡è¯†åˆ«æƒé‡ ===
    auto_detect_config = speechsdk.languageconfig.AutoDetectSourceLanguageConfig(
        languages=["en-US", "zh-CN"] 
    )

    # 3. è¯­éŸ³åˆæˆé…ç½®
    tts_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=tts_config)

    # 4. è¯†åˆ«å™¨
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
    recognizer = speechsdk.translation.TranslationRecognizer(
        translation_config=translation_config,
        audio_config=audio_config,
        auto_detect_source_language_config=auto_detect_config
    )

    # ã€æ–°å¢è¡¥ä¸ã€‘å¼ºåˆ¶è®¾ç½®ä¸ºâ€œè¿ç»­è¯†åˆ«â€æ¨¡å¼
    # å‘Šè¯‰ Azureï¼šæ¯ä¸€å¥è¯éƒ½è¦é‡æ–°çŒœè¯­è¨€ï¼Œä¸è¦ä¾èµ–æƒ¯æ€§ï¼
    recognizer.properties.set_property(
        property_id=speechsdk.PropertyId.SpeechServiceConnection_LanguageIdMode, 
        value='Continuous'
    )
    
    # === æ’­æ”¾å‡½æ•° ===
    def play_translation(text, language_code):
        voice_map = {
            "en": "en-US-AvaNeural",
            "zh-Hans": "zh-CN-XiaoxiaoNeural"
        }
        voice_name = voice_map.get(language_code, "en-US-AvaNeural")
        ssml_string = f"""
        <speak version='1.0' xml:lang='{language_code}'>
            <voice name='{voice_name}'>{escape(text)}</voice>
        </speak>
        """
        speech_synthesizer.speak_ssml_async(ssml_string)

    # === ç»“æœå¤„ç†å›è°ƒ ===
    def result_callback(evt):
        if evt.result.reason == speechsdk.ResultReason.TranslatedSpeech:
            src_lang = evt.result.properties.get(
                speechsdk.PropertyId.SpeechServiceConnection_AutoDetectSourceLanguageResult
            )
            text = evt.result.text
            
            # åˆ¤æ–­æ–‡æœ¬æ˜¯å¦çº¯è‹±æ–‡
            is_english_text = bool(re.search(r"[a-zA-Z]", text)) and not bool(re.search(r"[\u4e00-\u9fa5]", text))

            print(f"\n[Azureåˆ¤æ–­]: {src_lang} | [å®é™…æ–‡æœ¬]: {text}")

            # --- åœºæ™¯ 1: Azure è¯†åˆ«æ­£ç¡® (è¯´æ˜¯è‹±æ–‡ï¼Œä¹Ÿæ˜¯è‹±æ–‡) ---
            if "en" in src_lang:
                target_lang = "zh-Hans"
                trans_text = evt.result.translations.get(target_lang, "")
                print(f"[ç¿»è¯‘æˆåŠŸ]: {trans_text}")
                play_translation(trans_text, target_lang)

            # --- åœºæ™¯ 2: Azure è¯†åˆ«æ­£ç¡® (è¯´æ˜¯ä¸­æ–‡ï¼Œä¹Ÿæ˜¯ä¸­æ–‡) ---
            elif "zh" in src_lang and not is_english_text:
                target_lang = "en"
                trans_text = evt.result.translations.get(target_lang, "")
                print(f"[ç¿»è¯‘æˆåŠŸ]: {trans_text}")
                play_translation(trans_text, target_lang)

            # --- åœºæ™¯ 3: Azure è¯¯åˆ¤ (è¯´æ˜¯ä¸­æ–‡ï¼Œä½†å®é™…æ˜¯è‹±æ–‡) ---
            # è¿™å°±æ˜¯ä½ é‡åˆ°çš„æƒ…å†µï¼šAzureä»¥ä¸ºæ˜¯ä¸­æ–‡ï¼Œæ‰€ä»¥æ²¡è¿›è¡Œ"è‹±->ä¸­"ç¿»è¯‘
            elif "zh" in src_lang and is_english_text:
                print(">> [ç³»ç»Ÿè­¦å‘Š]: æ£€æµ‹åˆ°è‹±æ–‡ï¼Œä½†Azureå¤„äºä¸­æ–‡æ¨¡å¼ï¼Œå¯¼è‡´æœªç¿»è¯‘ã€‚")
                print(">> [å»ºè®®]: è¯·å°è¯•è¯´ä¸€ä¸ªæ›´é•¿çš„è‹±æ–‡å¥å­ï¼Œæˆ–è€…åœé¡¿ä¸€ä¸‹å†è¯´ã€‚")
                # è¿™é‡Œæˆ‘ä»¬ä¸æ’­æ”¾ï¼Œé¿å…æ’­æ”¾å‡ºè‹±æ–‡åŸæ–‡å¯¼è‡´æ··æ·†
            
            else:
                print(">> [å¿½ç•¥]: æ— æ³•ç¡®å®šçš„è¯­è¨€çŠ¶æ€ã€‚")

    recognizer.recognized.connect(result_callback)
    
    # å¼€å§‹
    print("--------------------------------------------------")
    print("ç³»ç»Ÿå·²å¯åŠ¨ã€‚ä¼˜å…ˆè¯†åˆ«è‹±æ–‡æ¨¡å¼ã€‚")
    print("æç¤ºï¼šå¦‚æœåˆ‡æ¢è¯­è¨€å¤±è´¥ï¼Œè¯·å°è¯•è¯´é•¿ä¸€ç‚¹çš„å¥å­ã€‚")
    print("--------------------------------------------------")
    recognizer.start_continuous_recognition()

    try:
        while True: time.sleep(0.5)
    except KeyboardInterrupt:
        recognizer.stop_continuous_recognition()

if __name__ == "__main__":
    start_voice_interpreter()

# æ”¯æŒçš„ç¿»è¯‘ç›®æ ‡è¯­ç§æœ‰ï¼š
# "è¯­ç§","ä»£ç  (å¿…å¡«)","å¤‡æ³¨"
# "ç®€ä½“ä¸­æ–‡","zh-Hans","æ³¨æ„ä¸æ˜¯ zh-CN (è¿™æ˜¯æºè¯­è¨€/TTSç”¨çš„ï¼Œç¿»è¯‘ç›®æ ‡å¿…é¡»ç”¨ Hans)"
# "ç¹ä½“ä¸­æ–‡","zh-Hant",""
# "è‹±è¯­","en","é€šç”¨è‹±è¯­"
# "æ—¥è¯­","ja",""
# "éŸ©è¯­","ko",""
# "æ³•è¯­","fr",""
# "å¾·è¯­","de",""
# "è¥¿ç­ç‰™è¯­","es",""
# "æ„å¤§åˆ©è¯­","it",""
# "ä¿„è¯­","ru",""
# "è‘¡è„ç‰™è¯­","pt",""
# "æ³°è¯­","th",""
# "è¶Šå—è¯­","vi",""
# "å°å°¼è¯­","id",""
# "é˜¿æ‹‰ä¼¯è¯­","ar",""

# ================================

# æ”¯æŒçš„æ£€æµ‹è¯­ç§æœ‰ï¼šï¼ˆä¸»è¦ä¸€èˆ¬æœ€å¤šåªæ”¾10ç§æ£€æµ‹è¯­ç§ï¼Œä¸ç„¶å½±å“è¯†åˆ«ç‡ï¼‰
# ğŸ‡¨ğŸ‡³ ä¸­æ–‡ç³»åˆ—
# è¯­è¨€åç§°	ä»£ç  (Locale ID)	å¤‡æ³¨
# ä¸­æ–‡ (æ™®é€šè¯ - ç®€ä½“)	zh-CN	æœ€å¸¸ç”¨
# ä¸­æ–‡ (æ™®é€šè¯ - ç¹ä½“/å°æ¹¾)	zh-TW	
# ä¸­æ–‡ (ç²¤è¯­ - ç®€ä½“)	yue-CN	å¹¿ä¸œè¯è¯†åˆ«
# ä¸­æ–‡ (é¦™æ¸¯ç²¤è¯­)	zh-HK	
# ä¸­æ–‡ (å´è¯­/ä¸Šæµ·è¯)	wuu-CN	éƒ¨åˆ†åŒºåŸŸæ”¯æŒ
# ä¸­æ–‡ (å››å·è¯)	zh-CN-sichuan	éƒ¨åˆ†åŒºåŸŸæ”¯æŒ
# ğŸ‡ºğŸ‡¸ è‹±è¯­ç³»åˆ—
# è¯­è¨€åç§°	ä»£ç 	å¤‡æ³¨
# è‹±è¯­ (ç¾å›½)	en-US	æœ€é€šç”¨
# è‹±è¯­ (è‹±å›½)	en-GB	
# è‹±è¯­ (æ¾³å¤§åˆ©äºš)	en-AU	
# è‹±è¯­ (å°åº¦)	en-IN	
# è‹±è¯­ (åŠ æ‹¿å¤§)	en-CA	
# ğŸŒ äºšæ´²å…¶ä»–
# è¯­è¨€åç§°	ä»£ç 
# æ—¥è¯­	ja-JP
# éŸ©è¯­	ko-KR
# æ³°è¯­	th-TH
# è¶Šå—è¯­	vi-VN
# å°å°¼è¯­	id-ID
# å°åº¦è¯­ (å°åœ°è¯­)	hi-IN
# ğŸŒ æ¬§æ´²
# è¯­è¨€åç§°	ä»£ç 
# æ³•è¯­ (æ³•å›½)	fr-FR
# å¾·è¯­ (å¾·å›½)	de-DE
# è¥¿ç­ç‰™è¯­ (è¥¿ç­ç‰™)	es-ES
# æ„å¤§åˆ©è¯­	it-IT
# ä¿„è¯­	ru-RU
# è‘¡è„ç‰™è¯­ (å·´è¥¿)	pt-BR